
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Was ist Facial Emotion Recognition? &#8212; Facial Emotion Recognition</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Menschliche Kommunikation" href="human_communication.html" />
    <link rel="prev" title="Facial Emotion Recognition" href="index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Facial Emotion Recognition</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="index.html">
   Facial Emotion Recognition
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Was ist Facial Emotion Recognition?
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="human_communication.html">
   Menschliche Kommunikation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="featureextraction.html">
   Mimikcodierung und Feature Extraction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="datasets.html">
   Daten(sätze)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="models.html">
   FER Ansätze
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="fem_impl.html">
   Implementation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="VideoTest.html">
   Selbsttrainiertes Modell per Webcam testen
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="criticism.html">
   Kritik
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="conclusion.html">
   Fazit
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="references.html">
   Quellen
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/definition.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jgrimm22/facial-emotion-recognition"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/jgrimm22/facial-emotion-recognition/issues/new?title=Issue%20on%20page%20%2Fdefinition.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aufbau-fer">
   Aufbau FER
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#agenda">
   Agenda
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="was-ist-facial-emotion-recognition">
<h1>Was ist Facial Emotion Recognition?<a class="headerlink" href="#was-ist-facial-emotion-recognition" title="Permalink to this headline">¶</a></h1>
<div class="admonition-definition admonition">
<p class="admonition-title">Definition</p>
<p>Facial Emotion Recognition ist die Erkennung von Gesichtsausdrücken und die damit verbundenen Emotionen durch ein maschinelles Lernverfahren.</p>
</div>
<p>Die automatische Erkennung von Emotionen durch maschinelle Lernverfahren ist der Prozess menschliche Emotionen aus Signalen, wie Gesichtsausdrücken oder Sprache zu extrahieren und zu erkennen.</p>
<p>Emotionen im Gesicht zu erkennen ist ein wichtiger Faktor in menschlicher Kommunikation, um die Absichten untereinander zu verstehen. Menschen schließen anhand von Gesichtsausdrücken und Stimmlagen auf die Gefühlszustände anderer Menschen. Das Interesse an automatischer Gesichtsemotionserkennung hat in den vergangenen Jahren mit der rasanten Entwicklung von KI-Techniken zugenommen.</p>
<p>Die Abkürzung FER wird sowohl für Facial Emotion Recognition als auch Facial Expression Recognition verwendet. Die beiden Begriffe werden in der Literatur häufig synonym verwendet.</p>
<!-- #region -->
<div class="section" id="aufbau-fer">
<h2>Aufbau FER<a class="headerlink" href="#aufbau-fer" title="Permalink to this headline">¶</a></h2>
<p>Die Facial Emotion Recognition setzt sich aus drei Komponenten zusammen, die egal welcher maschinelle Lernansatz verwendet wird, in irgendeiner Form benötigt werden.</p>
<p>Diese Komponenten sind zum einen die <strong>Gesichtserkennung</strong> und die <strong>Facial Component Detection</strong>, wobei Gesichtskomponenten, (z.B. Nase und Augen) oder Facial Landmarks im Gesicht erkannt werden. Des Weiteren findet eine <strong>Feature Extraction</strong> statt, in der die wichtigen Mekamle eines Bildes extrahiert werden. Schießlich wird bei der <strong>Klassifizierung</strong> das Bild mit Hilfe der extrahierten Merkmale einer Emotion zugeordnet.</p>
<p><img alt="Komponenten" src="_images/fer_process.png" /></p>
<p>Um ein gutes maschinelles Lernverfahren für die Facial Emotion Recognition zu entwickeln, ist es wichtig Emotionen und Mimik des Menschen zu verstehen und diese richtig zu beschreiben. Dies ist notwendig, um einer Emotion ein Label zuordnen zu können. Außerdem werden aussagekräftige Daten benötigt, um das FER-System trainieren zu können.</p>
<!-- #endregion -->
</div>
<div class="section" id="agenda">
<h2>Agenda<a class="headerlink" href="#agenda" title="Permalink to this headline">¶</a></h2>
<p>Um eine Facial Emotion Recognition durchführen zu können müssen einige Themen beachtet werden. Im folgenden wird ein Überblick über die einzelnen Komponenten gegeben, die für die Realisierung eines FER-Models benötigt werden:</p>
<ul class="simple">
<li><p>Menschliche Kommunikation</p></li>
<li><p>Feature Extraction</p></li>
<li><p>Datensätze</p></li>
<li><p>Modelle/FER-Ansätze</p></li>
<li><p>Implementiertes Modell</p></li>
<li><p>Kritik</p></li>
<li><p>Fazit</p></li>
</ul>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="index.html" title="previous page">Facial Emotion Recognition</a>
    <a class='right-next' id="next-link" href="human_communication.html" title="next page">Menschliche Kommunikation</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Jessica Hofmann, Julia Grimm<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>